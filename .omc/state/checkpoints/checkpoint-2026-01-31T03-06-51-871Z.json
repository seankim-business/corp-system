{
  "created_at": "2026-01-31T03:06:51.869Z",
  "trigger": "auto",
  "active_modes": {
    "autopilot": {
      "phase": "unknown",
      "originalIdea": ""
    },
    "ultrawork": {
      "original_prompt": "메가 프롬프트 (상위+서브+서브서브 에이전트 & 깊이 있는 QA 규약)\n\n> 이 레포와 app.nubabel.com을 위한 **풀스택 QA 에이전트 군단**을 설계·구현해줘.  \n> 목표:  \n> - 내가 이 프롬프트를 한 번 실행하면,  \n> - 상위 오케스트레이터 에이전트 + 여러 단계의 서브/서브서브 에이전트를 자동으로 정의하고,  \n> - 시지프스/ralph 스타일 에이전트가 그들을 부려서, “사실상 원샷에 가까운 QA/QC + 기능 수정”이 **유저 플로우 단위**로 계속 돌아가게 만드는 것.  \n>   \n> ---  \n> ### 0. 환경/자원 전제  \n> - 코드베이스: 현재 열려 있는 이 프로젝트 (app.nubabel.com).  \n> - 기준 진실: 이 서비스의 기획/요구사항/문서(기획서, Notion, README 등).  \n> - 사용 가능한 자원:  \n>   - Claude Code (코드 편집, 터미널, git, 테스트 실행 등)  \n>   - Claude in Chrome (실제 브라우저에서 유저처럼 클릭/네비게이션)  \n>   - Slack #it-test 채널, @Nubabel 에이전트 (유저 시뮬레이션/대화형 테스트)  \n>   - Railway CLI (빌드/배포/로그/테스트 모니터링)  \n> - 실행 모드 키워드: `ralph`, `sisyphus`, `ultrawork`, `ultraqa`, `autopilot`, `yolo mode`  \n>   - 단, **위험 작업(데이터 파괴/실제 결제 등)은 사람 승인 단계가 반드시 필요**하다.  \n>   \n> ---  \n> ### 1. 전체 구조 설계 (상위 → 서브 → 서브서브)  \n> 1.1 먼저, 이 프로젝트에 맞는 에이전트 계층 구조를 설계해라:  \n> - 최상위:  \n>   - “QA Architect / Orchestrator” 에이전트 1개  \n>   - 역할: 내가 한 줄 목표를 던지면, 플로우 단위로 작업을 쪼개고, 서브/서브서브 에이전트에게 일을 배분하고, 결과를 모으고, 다음 단계를 결정하는 두뇌.  \n> - 중간 레벨(서브에이전트, 5~10개 정도):  \n>   - 예:  \n>     - Flow-Planner: 유저 플로우 목록 정의 + 우선순위 결정  \n>     - Spec-Aligner: 기획/요구사항 vs 현재 코드/UX diff 도출  \n>     - Chrome-Tester: Claude in Chrome으로 실제 유저처럼 플로우 실행/검증  \n>     - Slack-Simulator: Slack #it-test에서 @Nubabel과 대화하며 “현실 유저 시나리오”를 흉내 내는 에이전트  \n>     - Fixer: 발견된 문제를 코드/설정/카피 레벨에서 실제로 수정  \n>     - Test-Builder: 캐릭터라이제이션/통합/E2E 테스트를 추가하는 역할  \n>     - Build-Monitor: Railway CLI로 빌드/로그/테스트를 감시하고, 실패 시 원인 분석  \n>     - Risk-Reporter: 남은 리스크/미커버 영역을 정리해 사람에게 보고  \n>   - 각 에이전트는 **단일 책임 원칙**을 갖고, 자신이 맡은 도메인만 처리한다.  \n> - 최하위 레벨(서브서브에이전트, 필요 시):  \n>   - 더 세부적인 반복 작업 담당 (예: 특정 플로우의 Chrome 시나리오 실행, 특정 모듈의 테스트 생성, 특정 로그 분석 등).  \n>   - 상위 서브에이전트가 이들을 호출하는 식으로 설계.  \n>   \n> 1.2 위 계층 구조에 대해:  \n> - 에이전트 이름  \n> - 계층(상위/서브/서브서브)  \n> - 책임 범위 / 목적  \n> - 사용 도구(Chrome, Slack, Railway, tests, git 등)  \n> - 입력/출력 포맷  \n> 을 표로 정리해라.  \n>   \n> ---  \n> ### 2. 에이전트 정의 템플릿 설계  \n> 2.1 이 프로젝트에서 사용할 **공통 에이전트 정의 템플릿**을 하나 만들고,  \n> - `.claude/agents/<agent-name>.md` 파일 구조를 다음을 포함하도록 설계해라:  \n>   - YAML frontmatter:  \n>     - `name`, `description`, `roles`, `tools`, `skills`, `tier`(상위/서브/서브서브) 등  \n>   - 본문:  \n>     - 이 에이전트의 시스템 프롬프트 (행동 규칙, 금지사항, 상위/하위 에이전트와의 통신 규칙)  \n>     - 예시 입력/출력 형식  \n> 2.2 이 템플릿을 실제 마크다운 예시(`.claude/agents/template.md`)로 작성해라.  \n>   \n> ---  \n> ### 3. 실제 에이전트 파일 생성 (상위 + 서브 + 서브서브)  \n> 3.1 위 구조와 템플릿을 바탕으로, 다음을 실제 파일로 생성해라:  \n> - 최상위 오케스트레이터 예: `.claude/agents/nubabel-qa-architect.md`  \n>   - 역할:  \n>     - 내가 “app.nubabel.com 전체를 기획 기반으로 QA/QC하고, 안 되는 부분은 알아서 고쳐줘” 같은 큰 목표를 던지면,  \n>     - 유저 플로우 정의 → 우선순위 선정 → 서브/서브서브 에이전트에게 작업 배분 → 진행 모니터링 → 결과 취합 → 리포팅까지 주도.  \n>   - 시스템 프롬프트 안에 다음 규칙을 포함해라:  \n>     - 항상 “Plan → Assign → Execute → Verify → Next” 루프를 돈다.  \n>     - 플로우 단위로 작업 스코프를 잡고, **서비스 전체 무차별 리팩토링은 절대 하지 않는다.**  \n>     - 위험 작업은 `HOLD: human review` 상태로 표시하고, 나에게 질문한다.  \n>     - 가능한 한 `ralph`, `sisyphus`, `ultrawork`, `ultraqa`, `autopilot`, `yolo`를 활용해, “멈추지 않고 끝까지 가는” 방향으로 행동한다.  \n> - 서브에이전트들 예:  \n>   - `.claude/agents/nubabel-flow-planner.md`  \n>   - `.claude/agents/nubabel-spec-aligner.md`  \n>   - `.claude/agents/nubabel-chrome-tester.md`  \n>   - `.claude/agents/nubabel-slack-simulator.md`  \n>   - `.claude/agents/nubabel-fixer.md`  \n>   - `.claude/agents/nubabel-test-builder.md`  \n>   - `.claude/agents/nubabel-build-monitor.md`  \n>   - `.claude/agents/nubabel-risk-reporter.md`  \n>   - (실제 필요에 따라 이름/역할은 조정해도 좋다)  \n> - 서브서브에이전트들 예:  \n>   - 특정 플로우/모듈 전용 서브서브에이전트 파일 2~3개 정도 예시로 생성해라.  \n>   - 예: `.claude/agents/nubabel-flow-signup-tester.md`, `.claude/agents/nubabel-flow-checkout-tester.md` 등  \n> 3.2 각 파일에는, 해당 역할에 맞는 시스템 프롬프트가 실제로 채워져 있어야 한다.  \n> - 예: Chrome-Tester는 Claude in Chrome 사용 규칙, 스텝 실행 방식, 실패 시 리포트 포맷 등을 상세히 포함.  \n> - Slack-Simulator는 #it-test에서 @Nubabel과 어떻게 대화하며 테스트할지, 어떤 대화 패턴을 흉내 낼지 등을 포함.  \n> - Fixer는 “버그 리포트 → 코드 수정 → 테스트 실행 → diff 요약” 루프를 포함.  \n> - Test-Builder는 캐릭터라이제이션/통합/E2E 테스트 작성 전략을 포함.  \n>   \n> ---  \n> ### 4. 시지프스/ralph와의 연계 설계  \n> 4.1 위에서 만든 에이전트들을 **시지프스/ralph/ultrawork/autopilot**이 활용할 수 있도록, 사용 예시를 정의해라:  \n> - 예:  \n>   - “이제 `nubabel-qa-architect` 에이전트를 시지프스 모드로 실행해서, app.nubabel.com 전체 QA를 시작해라.”  \n>   - 각 플로우별로 어떤 서브/서브서브 에이전트 조합을 호출해야 하는지, 호출 순서와 종료 조건을 적어라.  \n> 4.2 나(사람)가 나중에 쓸 “한 줄 명령 예시”도 몇 개 만들어라.  \n> - 예:  \n>   - “`nubabel-qa-architect`에게: ‘이번에는 신규 가입 + 결제 플로우만 yolo ultraqa 모드로 끝까지 QA/QC+수정해 줘’ 라고 지시하는 프롬프트”  \n>   - “테스트 없이 추가된 기능 전체를 플로우별로 나눠서, 가장 위험한 3개 플로우부터 잡게 하는 프롬프트”  \n>   \n> ---  \n> ### 5. 작업 방식  \n> - 1단계: 구조/표/템플릿을 텍스트로 먼저 설계.  \n> - 2단계: `.claude/agents/` 디렉터리에 필요한 파일들을 직접 생성/편집.  \n> - 3단계: `nubabel-qa-architect` 에이전트 기준으로, 실제 호출 예시(내가 나중에 복붙해서 쓸 프롬프트)까지 같이 제안.  \n>   \n> ---  \n> ### 6. 얕은 QA 금지 / 근본 원인 중심 사고  \n> 너와 네가 만드는 모든 상위/서브/서브서브 에이전트는, **겉핥기식 QA/QC를 절대 해서는 안 된다.**  \n> 아래 원칙을 시스템 레벨 행동 규칙으로 강하게 내재화해라:  \n>   \n> 6.1 유저 시나리오의 “폭”과 “깊이”  \n> - 단순 해피패스만 돌지 말고, 실제로 발생 가능한 디테일한 유저 시나리오를 최대한 많이 상상하고 실행해라.  \n>   - 정상 경로뿐 아니라:  \n>     - 잘못된 입력, 엣지 케이스, 느린 네트워크, 중간에 이탈했다 돌아오는 케이스, 중복 클릭, 여러 탭에서 동시에 조작하는 경우 등 **현실적인 악조건**을 포함해라.  \n>   - 각 플로우마다: 최소 한 개의 해피패스 + 여러 개의 비정상/엣지 시나리오를 반드시 포함한다.  \n> - 모든 시나리오는 **Slack(#it-test, @Nubabel)과 웹(app.nubabel.com)을 오가며**, 실제 유저처럼 행동하는 방식으로 검증한다.  \n>   \n> 6.2 “정합성” 검증: 한 화면만 보지 말고 전체 시스템을 의심  \n> - 하나의 화면/엔드포인트만 보고 “괜찮다”고 결론 내리지 말고, 항상 다음을 함께 점검해라:  \n>   - 같은 데이터가 다른 화면/기능에서 어떻게 보이는지  \n>   - Slack 알림/로그/이벤트와 실제 화면/DB 상태가 일치하는지  \n>   - 관련된 다른 플로우(예: 가입 → 이메일 인증 → 로그인 → 결제)와의 연결이 끊기지 않았는지  \n> - 모든 플로우에 대해 **“정합성 체크리스트”**를 자동으로 만들고, QA 시 매번 그 체크리스트를 따라가며 Slack/사이트/로그를 오가면서 검증해라.  \n>   \n> 6.3 에러 수정 시 “근본 원인”부터  \n> - 발견된 에러/버그/이상 동작에 대해, 항상 세 단계로 생각하고 행동해라:  \n>   1) 표면 증상: 지금 눈앞에서 터지는 에러/이상 동작  \n>   2) 직접 원인: 어떤 코드/설정/데이터 조합이 이 증상을 만들었는지  \n>   3) 근본 원인: 왜 이런 상황이 구조적으로 다시 생길 수밖에 없는지 (설계/추상화/경계 정의/테스트 부재 등)  \n> - 수정할 때는, 가능하면 (3) 근본 원인에 최대한 가까운 지점까지 손대는 것을 우선 고려해라.  \n>   - 단, 리스크가 크면:  \n>     - 최소 수정(핫픽스) + TODO/이슈 등록 + 테스트 추가까지 하고,  \n>     - 더 큰 구조 변경은 별도 플로우/스프린트로 분리한다.  \n>   \n> 6.4 “지레짐작 괜찮다” 금지, 끝없는 의심 모드  \n> - “아마 괜찮을 거다”, “이 정도면 됐다”라는 가정을 절대로 하지 말고, 기본 태도를 **끝없는 의심 모드**로 유지해라.  \n>   - 항상 스스로에게 질문해라:  \n>     - “이게 정말 항상 맞는가?”  \n>     - “다른 환경/브라우저/디바이스/권한/상태에서도 그대로 동작할까?”  \n>     - “이 수정이 다른 플로우를 깨지 않았다는 증거가 있는가?”  \n> - 증거가 없으면, **“괜찮다”고 결론 내리지 말고, 추가 검증 시나리오를 자동으로 설계하고 실행하라.**  \n>   \n> 6.5 수정 전에 “현재 환경”을 다각도로 점검  \n> - 어떤 코드를 수정하기 전에, 먼저 현재 환경을 가능한 한 많이 관찰/수집해라:  \n>   - 브라우저: 다양한 브라우저/디바이스/뷰포트에서 실제로 어떻게 보이는지  \n>   - Slack/로그: 관련 알림/에러/이벤트가 어떻게 발생/기록되는지  \n>   - Railway/서버: 빌드/릴리즈 버전, 환경 변수, 연결된 서비스 상태  \n>   - 테스트/모니터링: 기존 자동 테스트/헬스 체크가 무엇을 커버하고 무엇을 커버하지 않는지  \n> - 이 정보를 바탕으로 “가장 안전하면서도 효과적인 수정 전략”을 계획하고, 그다음에만 코드를 수정해라.  \n>   \n> 6.6 수정 후에는 여러 각도에서 재검증  \n> - 수정이 끝나면, 반드시 다음을 수행해라:  \n>   - 수정한 플로우를 해피패스 + 비정상/엣지 시나리오로 다시 돌려본다.  \n>   - 관련된 다른 플로우도 최소 한 번씩 sanity check한다.  \n>   - Slack 알림/로그/데이터 정합성까지 포함해서, “수정 전후 비교 리포트”를 남긴다.  \n> - “테스트 1개 통과 → 끝”이 아니라, 가능한 한 **여러 각도에서 교차 검증**한 뒤에만 플로우를 “임시로 안정” 상태로 표시해라.  \n>   \n> 6.7 사람에게 보여줄 때도 “겉멋 금지”  \n> - 나(사람)에게 리포트할 때, “겉으로 보기엔 그럴듯하지만 실제로는 안 돌려본 시나리오”를 절대 포장하지 마라.  \n> - 항상:  \n>   - 어떤 시나리오를 실제로 실행했고,  \n>   - 어떤 조합/환경은 아직 못 돌려봤고,  \n>   - 어떤 리스크가 남아 있는지  \n> 를 솔직하게 적어라.  \n>   \n> 이 6.x 원칙들은 **모든 에이전트(상위/서브/서브서브)의 시스템 프롬프트 안에 공통 규약으로 녹여 넣어라.**  \n> 특히 `nubabel-qa-architect`, Chrome-Tester, Slack-Simulator, Fixer, Test-Builder 계열 에이전트는, 위 규칙을 **행동의 기본값**으로 삼아야 한다.\n"
    }
  },
  "todo_summary": {
    "pending": 0,
    "in_progress": 0,
    "completed": 0
  },
  "wisdom_exported": true
}